{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6efb6548",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">Evaluation of Sentiment Analysis classifiers and News titles WebSrap</h1>\n",
    "<h3>Motivation:</h3>\n",
    "<p><b>News Sentiment Analysis</b> is one of the many applications for NLP, and the idea behind this notebook was to create a way of, automatically, create a news dataset by webscrapping data from different news web-sites and use existing classifiers to help/ classify each title.</p>\n",
    "<h3>News titles sources:</h3>\n",
    "<table >\n",
    "    <tr>\n",
    "        <th style=\"text-align:center\">CNN</th>\n",
    "        <th style=\"text-align:center\">GoodNews Network</th>\n",
    "    <tr>\n",
    "    <tr>\n",
    "        <td><img src='data:image/png;base64,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'></td>\n",
    "        <td><img src='data:image/png;base64,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'></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<p><strong>CNN general news</strong></p>\n",
    "<p><strong>GoodNews Network - general \"positive\" news</strong></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65050e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/salvado/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "2023-02-22 15:57:23.468159: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-22 15:57:23.468181: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "# importing libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "\n",
    "# Selenium\n",
    "from selenium import webdriver   # for webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait  # for implicit and explict waits\n",
    "from selenium.webdriver.chrome.options import Options  # for suppressing the browser\n",
    "\n",
    "\n",
    "#nlp\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import unicodedata\n",
    "import contractions\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "#regular expressions\n",
    "import re\n",
    "\n",
    "# pretrained (sentiment classification)\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# textBlob \n",
    "from textblob import TextBlob\n",
    "\n",
    "# flair\n",
    "import flair\n",
    "\n",
    "# loop status viewer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc98d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the driver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "789d98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goodnews_scrap(web='https://www.goodnewsnetwork.org/')-> list:\n",
    "    \n",
    "    driver.get(web)\n",
    "    article_title = []\n",
    "    soup_goodnews = BeautifulSoup(driver.page_source)\n",
    "    news_list = soup_goodnews.find_all('div', class_='td-block-row')\n",
    "    for news in news_list:\n",
    "        for header in news.find_all('h3'):\n",
    "            if len(header.get_text().split()) > 0:\n",
    "                article_title.append(header.get_text())\n",
    "\n",
    "    return article_title\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda481e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goodnews_scrap_v2(web='https://www.goodnewsnetwork.org/', n_articles = 10)-> list:\n",
    "    \"\"\"\n",
    "        This function is to perform webscrap from the website Goodnews. This website is a website that\n",
    "        will load more articles when one scrolldown. So we'll use Selenium to help us with that.\n",
    "        We define also the number of articles we want to scrap.\n",
    "        \n",
    "    :param web: Goodnews WebSite \n",
    "    :param n_articles:  number of articles to scrap from the website  \n",
    "    :return: list of headers from each article-\n",
    "    \"\"\"\n",
    "    \n",
    "    driver.get(web)\n",
    "    screen_height = driver.execute_script('return window.screen.height;')  # get the height of one screen\n",
    "    scrolling = True\n",
    "    # for scrolling purposes\n",
    "    scroll_init = 0\n",
    "    i=0\n",
    "    \n",
    "    # init list article\n",
    "    article_title = []\n",
    "    \n",
    "    while scrolling:\n",
    "        driver.execute_script('window.scrollTo({scroll_init}, {screen_height});'.format(scroll_init=scroll_init, screen_height=screen_height))\n",
    "        i += 1\n",
    "        scroll_init = screen_height\n",
    "        screen_height = scroll_init + screen_height\n",
    "        time.sleep(2)\n",
    "        \n",
    "        soup_goodnews = BeautifulSoup(driver.page_source)\n",
    "        news_list = soup_goodnews.find_all('div', class_='td-block-row')\n",
    "        for news in news_list:\n",
    "            for header in news.find_all('h3'):\n",
    "                if len(header.get_text().split()) > 0:\n",
    "                    article_title.append(header.get_text())\n",
    "                    if len(article_title) > n_articles:\n",
    "                        scrolling = False\n",
    "                        break\n",
    "                        \n",
    "    return article_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "808fb3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_scrap(web='https://edition.cnn.com/'):\n",
    "    driver.get(web)\n",
    "    soup_cnn = BeautifulSoup(driver.page_source)\n",
    "    article_title = []\n",
    "    for section in soup_cnn.find_all('section')[1:]:\n",
    "        if len(section.find_all('ul')) > 0:\n",
    "            for ul_elem in section.find_all('ul'):\n",
    "                for elem in ul_elem.find_all('li'):\n",
    "                    if len(elem.get_text().split()) > 0:\n",
    "                        article_title.append(elem.get_text())\n",
    "    return article_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5adb6e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_scrapv2(web='https://edition.cnn.com/world'):\n",
    "    \"\"\"\n",
    "        This function is to perform webscrap from the website CNN. This function is going to scrap each \"layer\",\n",
    "        from the nav-bar on the top and the page \"in it\". (Africa, Europe, Americas, etc.)\n",
    "        \n",
    "    :param web: CNN World WebSite \n",
    "    :return: list of headers from each article-\n",
    "    \"\"\"\n",
    "    driver.get(web)\n",
    "    cnn_world = BeautifulSoup(driver.page_source)\n",
    "    \n",
    "    nav_items = cnn_world.find_all('div', class_='header__nav-item')\n",
    "    #print(nav_items)\n",
    "    url_list = []\n",
    "    for url in nav_items:\n",
    "        url_list.append(url.find('a')['data-zjs-destination_url'])\n",
    "    article_title = []    \n",
    "    for url in url_list:\n",
    "        driver.get(url)\n",
    "        page_soup = BeautifulSoup(driver.page_source)\n",
    "        tmp = page_soup.find_all('section', class_='layout__wrapper')[0]\n",
    "        for header in tmp.find_all('div', class_='container__headline'):\n",
    "            if len(header.get_text().split()) > 0:\n",
    "                article_title.append(header.get_text(strip=True))\n",
    "\n",
    "    return article_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebffdd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodnews 420\n",
      "CNN 185\n"
     ]
    }
   ],
   "source": [
    "goodnews = goodnews_scrap_v2(n_articles=400)\n",
    "cnn = cnn_scrapv2()\n",
    "\n",
    "print('Goodnews {}'.format(len(goodnews)))\n",
    "print('CNN {}'.format(len(cnn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7630e562",
   "metadata": {},
   "source": [
    "<p>Combine together the two lists of article headers</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd18ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_list = goodnews\n",
    "titles_list.extend(cnn)\n",
    "del goodnews\n",
    "del cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8407e50",
   "metadata": {},
   "source": [
    "<h3>Text preprocessing:</h3>\n",
    "<ul>\n",
    "    <li>remove accented characters from strings use UniDecode;  <b>check :D</b></li>\n",
    "    <li>remove punctuation;  <b>check :D</b></li>\n",
    "    <li>make everyword lowercase;  <b>check :D</b></li>\n",
    "    <li>if present: remove the \\n \\t, etc from the strings;  <b>check :D</b></li>\n",
    "    <li>try remove stopwords;  <b>check :D</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5a2e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text: str, stop_word=True)-> str:\n",
    "    \"\"\"\n",
    "    Function to preprocess text.\n",
    "    \"\"\"\n",
    "    tmp = []\n",
    "    for word in text.split():\n",
    "        if word in list(contractions.contractions_dict.keys()):\n",
    "            tmp.append(contractions.contractions_dict[word])\n",
    "        elif re.findall(r\"[A-Za-z]+\"r\"'\"+r\"[A-Za-z]\", word):\n",
    "            split_at = re.search(r\"[']\", word).span()[0]\n",
    "            word = word[0:split_at]\n",
    "            tmp.append(word)\n",
    "        elif re.findall(r\"[a-zA-z0-9]+\"r\"-\"+r\"[a-zA-z0-9]\", word):\n",
    "            l =re.split(r'-', word)\n",
    "            tmp.extend(l)\n",
    "        else:\n",
    "            tmp.append(word)\n",
    "    text = ' '.join(tmp)\n",
    "    text = text.translate(str.maketrans('','', punctuation))  # remove punctutations\n",
    "    text = text.lower()\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    if stop_word:\n",
    "        text = [word for word in text.split() if word not in STOPWORDS]\n",
    "        text = ' '.join(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0595da",
   "metadata": {},
   "source": [
    "<h3>Definition of the functions for each classifier.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f19a5b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_vader(articles: list, dataframe_is_or_no=True)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        This function will classify text based on the Vader Intensity analyser.\n",
    "        \n",
    "    :param articles: list of titles\n",
    "    :param dataframe_is_or_no:  to return a list of classification or Dataframe\n",
    "    :return: list or DataFrame\n",
    "    \"\"\"\n",
    "    DS = SentimentIntensityAnalyzer()\n",
    "    articles_ = []\n",
    "    article_class = []\n",
    "    for article in tqdm(articles):\n",
    "        text_original_classified = DS.polarity_scores(article)\n",
    "        text_processed = text_preprocessing(article, False)\n",
    "        text_processed_classified = DS.polarity_scores(text_processed)\n",
    "        if dataframe_is_or_no:\n",
    "            articles_.append([article, float(text_original_classified['compound']), text_processed, float(text_processed_classified['compound'])])\n",
    "        else:\n",
    "            article_class.append([text_original_classified['compound'], text_processed_classified['compound']])\n",
    "    if dataframe_is_or_no:        \n",
    "        return pd.DataFrame(articles_, columns=['Original', 'Original Sent', 'Processed', 'Processed Sent'])\n",
    "    else:\n",
    "        return article_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f07d74e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_Texblob(articles: list, dataframe_is_or_no=True)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        This function will classify text based on TextBlob analyser.\n",
    "        \n",
    "    :param articles: list of titles\n",
    "    :param dataframe_is_or_no:  to return a list of classification or Dataframe\n",
    "    :return: list or DataFrame\n",
    "    \"\"\"\n",
    "    articles_ = []\n",
    "    article_class = []\n",
    "    for article in tqdm(articles):\n",
    "        text_original_classified = TextBlob(article).sentiment\n",
    "        text_processed = text_preprocessing(article, False)\n",
    "        text_processed_classified = TextBlob(text_processed).sentiment\n",
    "        if dataframe_is_or_no:\n",
    "            articles_.append([article, float(text_original_classified[0]), text_processed, float(text_processed_classified[0])])\n",
    "        else:\n",
    "            article_class.append([text_original_classified[0], text_processed_classified[0]])\n",
    "        \n",
    "    if dataframe_is_or_no:        \n",
    "        return pd.DataFrame(articles_, columns=['Original', 'Original Sent', 'Processed', 'Processed Sent'])\n",
    "    else:\n",
    "        return article_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3720a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasify_text_flair(articles: list, dataframe_is_or_no=True)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        This function will classify text based on Flair analyser.\n",
    "        \n",
    "    :param articles: list of titles\n",
    "    :param dataframe_is_or_no:  to return a list of classification or Dataframe\n",
    "    :return: list or DataFrame\n",
    "    \"\"\"\n",
    "    articles_ = []\n",
    "    article_class = []\n",
    "    flair_sentiment = flair.models.TextClassifier.load('en-sentiment')\n",
    "    for article in tqdm(articles):\n",
    "        text_original_classified = flair.data.Sentence(article)\n",
    "        flair_sentiment.predict(text_original_classified)\n",
    "        sentiment_o = text_original_classified.score\n",
    "        if re.findall('negative', str(text_original_classified.labels[0]), re.IGNORECASE):\n",
    "            # print('not cool')\n",
    "            sentiment_o = -1 * float(sentiment_o)\n",
    "\n",
    "        text_processed = text_preprocessing(article, False)\n",
    "        text_processed_classified = flair.data.Sentence(text_processed)\n",
    "        flair_sentiment.predict(text_processed_classified)\n",
    "        sentiment_p = text_processed_classified.score\n",
    "        if re.findall('negative', str(text_processed_classified.labels[0]), re.IGNORECASE):\n",
    "            # print('not cool')\n",
    "            sentiment_p = -1 * float(sentiment_p)\n",
    "        \n",
    "        \n",
    "        if dataframe_is_or_no:\n",
    "            articles_.append([article, sentiment_o, text_processed, sentiment_p])\n",
    "        else:\n",
    "            article_class.append([sentiment_o, sentiment_p])\n",
    "        \n",
    "    if dataframe_is_or_no:        \n",
    "        return pd.DataFrame(articles_, columns=['Original', 'Original Sent', 'Processed', 'Processed Sent'])\n",
    "    else:\n",
    "        return article_class  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b641d9ad",
   "metadata": {},
   "source": [
    "<h3>Run each function of the titles list</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29b46b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 605/605 [00:51<00:00, 11.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((605, 4), (605, 4), (605, 4))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_df = classify_text_vader(titles_list)\n",
    "textblob_df = classify_text_Texblob(titles_list)\n",
    "flair_df = clasify_text_flair(titles_list)\n",
    "vader_df.shape, textblob_df.shape, flair_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba795a9",
   "metadata": {},
   "source": [
    "<h3>Result Dataframe</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24eb11ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>O_Vader</th>\n",
       "      <th>O_TextBlob</th>\n",
       "      <th>O_Flair</th>\n",
       "      <th>Processed</th>\n",
       "      <th>P_Vader</th>\n",
       "      <th>P_TextBlob</th>\n",
       "      <th>P_Flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good News in History, February 22</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.991240</td>\n",
       "      <td>good news in history february 22</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.996779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior With No Car Walks to Work–But After She...</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.923491</td>\n",
       "      <td>senior with no car walks to workbut after she ...</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.994564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Original  O_Vader  O_TextBlob  \\\n",
       "0                  Good News in History, February 22   0.4404         0.7   \n",
       "1  Senior With No Car Walks to Work–But After She...  -0.2960         0.0   \n",
       "\n",
       "    O_Flair                                          Processed  P_Vader  \\\n",
       "0  0.991240                   good news in history february 22   0.4404   \n",
       "1 -0.923491  senior with no car walks to workbut after she ...  -0.2960   \n",
       "\n",
       "   P_TextBlob   P_Flair  \n",
       "0         0.7  0.996779  \n",
       "1         0.0 -0.994564  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict = {'Original':vader_df['Original'],\n",
    "          'O_Vader': vader_df['Original Sent'],\n",
    "          'O_TextBlob': textblob_df['Original Sent'],\n",
    "          'O_Flair': flair_df['Original Sent'],\n",
    "          'Processed':vader_df['Processed'], \n",
    "          'P_Vader':vader_df['Processed Sent'],\n",
    "          'P_TextBlob': textblob_df['Processed Sent'],\n",
    "          'P_Flair': flair_df['Processed Sent']}\n",
    "df = pd.DataFrame.from_dict(df_dict)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b39beb4",
   "metadata": {},
   "source": [
    "<h3>Time to use the information from all the 3 classifiers to create a final dataset.</h3>\n",
    "<p>We are going to use the majority vote to classify all the articles titles.</p>\n",
    "<p>Since none of these classifiers (not ML models except Flair) are \"trained\" specifically for the subjects in the titles specifically, we will try to use them together, the chance to have better results is higher. but we'll check that with labelled data.</p>\n",
    "<p><b>(note: initially I had defined different intervals, but these ones \"performed\" i little better)</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4580c61",
   "metadata": {},
   "source": [
    "<p>For the <strong>Vader Classification</strong>:</p>\n",
    "<ul>\n",
    "    <li>Negative : less than -0.5</li>\n",
    "    <li>Neutral: -0.5 to 0.5</li>\n",
    "    <li>Positive: more than 0.5</li>\n",
    "</ul>\n",
    "\n",
    "<p>For the <strong>TextBlob Classification</strong>:</p>\n",
    "<ul>\n",
    "    <li>Negative : less than -0.5</li>\n",
    "    <li>Neutral: -0.5 to 0.5</li>\n",
    "    <li>Positive: more than 0.5</li>\n",
    "</ul>\n",
    "\n",
    "<p>For the <strong>Flair Classification</strong>:</p>\n",
    "<ul>\n",
    "    <li>Negative : less than -0.5</li>\n",
    "    <li>Neutral: -0.5 to 0.5</li>\n",
    "    <li>Positive: more than 0.5</li>\n",
    "</ul>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f14dc387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_classification(dataframe: pd.DataFrame)-> pd.DataFrame:\n",
    "    # original_columns = ['O_Vader', 'O_TextBlob', 'O_Flair', 'P_Vader', 'P_TextBlob', 'P_Flair' ]\n",
    "    # withou Flair\n",
    "    original_columns = ['O_Vader', 'O_TextBlob', 'P_Vader', 'P_TextBlob']\n",
    "    punct = []\n",
    "    for idx in dataframe.index:\n",
    "        neg = 0\n",
    "        neutral = 0\n",
    "        pos = 0\n",
    "        for column in original_columns:\n",
    "            if dataframe[column][idx] < -0.5:\n",
    "                neg += 1\n",
    "                dataframe[column][idx] = 'negative'\n",
    "            elif -0.5 <= dataframe[column][idx] <= 0.5:\n",
    "                neutral += 1\n",
    "                dataframe[column][idx] = 'neutral'\n",
    "            elif dataframe[column][idx] > 0.5:\n",
    "                pos += 1\n",
    "                dataframe[column][idx] = 'positive'\n",
    "        punct.append([neg, neutral, pos])\n",
    "            \n",
    "    return punct, dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07f628d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22404/2013728201.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[column][idx] = 'neutral'\n"
     ]
    }
   ],
   "source": [
    "lista, dataframe = majority_classification(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "495f6df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22404/2393953630.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  News_df_majority.dropna(axis=0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "classification = ['negative', 'neutral', 'positive']\n",
    "final = []\n",
    "for ele in lista:\n",
    "    if ele[0] == ele[1] and ele[0] == ele[2]:\n",
    "        final.append('Nan')\n",
    "    else:\n",
    "        final.append(classification[np.array(ele).argmax()])\n",
    "    \n",
    "df['Classification'] = final\n",
    "News_df_majority = df[['Original', 'Classification']]\n",
    "News_df_majority.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7beef834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good News in History, February 22</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior With No Car Walks to Work–But After She...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dutch Woman Smashes a World Record Unbroken Fo...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MDMA and Psilocybin-Assised Psychotherapy Appr...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First of Its Kind Discovery in Mali: Vast Rese...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Original Classification\n",
       "0                  Good News in History, February 22       positive\n",
       "1  Senior With No Car Walks to Work–But After She...        neutral\n",
       "2  Dutch Woman Smashes a World Record Unbroken Fo...        neutral\n",
       "3  MDMA and Psilocybin-Assised Psychotherapy Appr...        neutral\n",
       "4  First of Its Kind Discovery in Mali: Vast Rese...       positive"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "News_df_majority.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fa1c05",
   "metadata": {},
   "source": [
    "<h3>To evaluate if this method for creating a news Title dataset is at least, anygood, we'll use labelled data from Kaggle to try it out.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca98fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial = pd.read_csv('kaggle_data/all-data.csv',delimiter=',', encoding='latin-1', header=None).fillna('')\n",
    "y = financial[0]\n",
    "x = financial[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "955ab875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4846/4846 [07:43<00:00, 10.45it/s]\n"
     ]
    }
   ],
   "source": [
    "vader_df = classify_text_vader(x)\n",
    "textblob_df = classify_text_Texblob(x)\n",
    "flair_df = clasify_text_flair(x)\n",
    "# vader_df.shape, textblob_df.shape, flair_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47c7c8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>O_Vader</th>\n",
       "      <th>O_TextBlob</th>\n",
       "      <th>Processed</th>\n",
       "      <th>P_Vader</th>\n",
       "      <th>P_TextBlob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>according to gran  the company has no plans to...</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>technopolis plans to develop in stages an area...</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>the international electronic industry company ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>-0.064802</td>\n",
       "      <td>with the new production plant the company woul...</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>-0.064802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>according to the company s updated strategy fo...</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>-0.016667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Original  O_Vader  O_TextBlob  \\\n",
       "0  According to Gran , the company has no plans t...  -0.1280    0.000000   \n",
       "1  Technopolis plans to develop in stages an area...  -0.2960    0.083333   \n",
       "2  The international electronic industry company ...   0.0000    0.000000   \n",
       "3  With the new production plant the company woul...   0.8555   -0.064802   \n",
       "4  According to the company 's updated strategy f...   0.6705    0.000000   \n",
       "\n",
       "                                           Processed  P_Vader  P_TextBlob  \n",
       "0  according to gran  the company has no plans to...  -0.1280    0.000000  \n",
       "1  technopolis plans to develop in stages an area...  -0.2960    0.083333  \n",
       "2  the international electronic industry company ...   0.0000    0.000000  \n",
       "3  with the new production plant the company woul...   0.8555   -0.064802  \n",
       "4  according to the company s updated strategy fo...   0.6705   -0.016667  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict = {'Original':vader_df['Original'],\n",
    "          'O_Vader': vader_df['Original Sent'],\n",
    "          'O_TextBlob': textblob_df['Original Sent'],\n",
    "           'O_Flair': flair_df['Original Sent'],\n",
    "          'Processed':vader_df['Processed'], \n",
    "          'P_Vader':vader_df['Processed Sent'],\n",
    "          'P_TextBlob': textblob_df['Processed Sent'],\n",
    "           'P_Flair': flair_df['Processed Sent']\n",
    "          }\n",
    "\n",
    "# without Flair because it performed poorly\n",
    "df_dict = {'Original':vader_df['Original'],\n",
    "          'O_Vader': vader_df['Original Sent'],\n",
    "          'O_TextBlob': textblob_df['Original Sent'],\n",
    "          'Processed':vader_df['Processed'], \n",
    "          'P_Vader':vader_df['Processed Sent'],\n",
    "          'P_TextBlob': textblob_df['Processed Sent'],\n",
    "          }\n",
    "\n",
    "df = pd.DataFrame.from_dict(df_dict)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75ba2676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22404/4016931059.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[column][idx] = 'neutral'\n"
     ]
    }
   ],
   "source": [
    "lista, dataframe = majority_classification(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3b77caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vader = dataframe['P_Vader']\n",
    "y_textblob = dataframe['P_TextBlob']\n",
    "#y_flair = dataframe['P_Flair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c200d078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22404/1713618693.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  News_df.dropna(axis=0,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "classification = ['negative', 'neutral', 'positive']\n",
    "final = []\n",
    "for ele in lista:\n",
    "    if ele[0] == ele[1] and ele[0] == ele[2]:\n",
    "        final.append('Nan')\n",
    "    else:\n",
    "        final.append(classification[np.array(ele).argmax()])\n",
    "    \n",
    "df['Classification'] = final\n",
    "News_df = df[['Original', 'Classification']]\n",
    "News_df.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37388866",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = News_df['Classification']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "585cd4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6004952538175815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a482b111",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.47      0.07      0.12       604\n",
    "     neutral       0.60      0.98      0.75      2879\n",
    "    positive       0.65      0.03      0.05      1363\n",
    "\n",
    "    accuracy                           0.60      4846\n",
    "   macro avg       0.58      0.36      0.31      4846\n",
    "    weighted avg       0.60      0.60      0.47      4846\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6655474",
   "metadata": {},
   "source": [
    "<h3>This method didn't perform very well and that was expected, because of the nature of the \"classifiers\"</h3>\n",
    "<p>This is why, according to subject, we train/ develop specific models. However, it was a good exercise.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
